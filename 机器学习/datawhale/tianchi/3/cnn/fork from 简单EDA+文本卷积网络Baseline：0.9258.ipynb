{"cells":[{"cell_type":"markdown","source":"# 基于文本卷积网络的Baseline\n* 线上0.9258","metadata":{}},{"cell_type":"code","source":"# 安装扩展包时请使用阿里云镜像源  install packages\n!pip install pandas==0.23.4 -i \"https://mirrors.aliyun.com/pypi/simple/\"\n!pip install numpy==1.19.0 -i \"https://mirrors.aliyun.com/pypi/simple/\"\n!pip install wrapt --ignore-installed -i \"https://mirrors.aliyun.com/pypi/simple/\"\n!pip install tensorflow==1.14.0 -i \"https://mirrors.aliyun.com/pypi/simple/\"\n!pip install keras==2.3.1 -i \"https://mirrors.aliyun.com/pypi/simple/\"\n!pip install bert4keras -i \"https://mirrors.aliyun.com/pypi/simple/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\nfrom keras.layers import *\nfrom keras.models import Model\nfrom keras.optimizers import Adam\n\nfrom bert4keras.snippets import sequence_padding, DataGenerator\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"%%time\ndf_train = pd.read_csv('datalab/72510/train_set.csv', sep='\\t')\ndf_test = pd.read_csv('datalab/72510/test_a.csv', sep='\\t')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 类别分布\n* 科技类的样本数量最多：38918\n* 星座类的样本数量最少：908","metadata":{}},{"cell_type":"code","source":"df_train['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_train['text'] = df_train['text'].apply(lambda x: list(map(lambda y: int(y), x.split())))\ndf_test['text'] = df_test['text'].apply(lambda x: list(map(lambda y: int(y), x.split())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 文本长度分布\n* 训练集有20万条文本，测试集a有5万条文本\n* 训练集和测试集a的文本长度分布基本一致，应该是从相同分布的数据集中划分出来的\n* 训练集：文本长度的均值约为908字符，中值为676字符，最短文本为2字符，最长文本为57921字符\n* 测试集a：文本长度的均值约为910字符，中值为676字符，最短文本为14字符，最长文本为41861字符","metadata":{}},{"cell_type":"code","source":"df_train['text'].map(lambda x: len(x)).describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['text'].map(lambda x: len(x)).describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 构造词典\n* 总共6869个字符，从0到7549，中间不连续，有缺失\n* 出现频率最高的字符Top10：3750，648，900，3370，6122，4464，7399，4939，3659，4811","metadata":{}},{"cell_type":"code","source":"%%time\nvocab = dict()\nfor text in df_test['text']:\n    for word in text:\n        if vocab.get(word):\n            vocab[word] += 1\n        else:\n            vocab[word] = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(vocab)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chars = sorted(vocab.items(), key=lambda x: x[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chars[:10]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chars[-10:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chars = sorted(vocab.items(), key=lambda x: x[1], reverse=True)\nchars[:10]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 训练","metadata":{}},{"cell_type":"markdown","source":"## 超参数","metadata":{}},{"cell_type":"code","source":"SEED = 2020\nnum_classes = 14\nvocabulary_size = 7600\n\nmaxlen = 1024\nbatch_size = 512\nembedding_dim = 256\nnum_filters = 512\nfilter_sizes = [3, 4, 5]\ndrop = 0.5\nlr = 1e-4\nepochs = 20","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 加载数据","metadata":{}},{"cell_type":"code","source":"df_train, df_valid = train_test_split(df_train, test_size=0.2, random_state=SEED)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(df):\n    \"\"\"加载数据\"\"\"\n    D = list()\n    for _, row in df.iterrows():\n        text = row['text']\n        label = row['label']\n        D.append((text, int(label)))\n    return D","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = load_data(df_train)\nvalid_data = load_data(df_valid)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class data_generator(DataGenerator):\n    \"\"\"数据生成器\"\"\"\n\n    def __init__(self, data, batch_size=32, buffer_size=None, random=False):\n        super().__init__(data, batch_size, buffer_size)\n        self.random = random\n\n    def __iter__(self, random=False):\n        batch_token_ids, batch_labels = [], []\n        for is_end, (text, label) in self.sample(random):\n            token_ids = text[:maxlen] if len(text) > maxlen else text + (maxlen - len(text)) * [0]\n            batch_token_ids.append(token_ids)\n            batch_labels.append([label])\n            if len(batch_token_ids) == self.batch_size or is_end:\n                batch_token_ids = sequence_padding(batch_token_ids)\n                batch_labels = sequence_padding(batch_labels)\n                yield [batch_token_ids], batch_labels\n                batch_token_ids, batch_labels = [], []\n\n    def forfit(self):\n        while True:\n            for d in self.__iter__(self.random):\n                yield d","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = data_generator(train_data, batch_size, random=True)\nvalid_generator = data_generator(valid_data, batch_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 构建模型（文本卷积网络）","metadata":{}},{"cell_type":"code","source":"# 输入\ninputs = Input(shape=(maxlen,), dtype='int32')\n\n# 嵌入层\nembedding = Embedding(\n    input_dim=vocabulary_size,\n    output_dim=embedding_dim,\n    input_length=maxlen\n)(inputs)\nreshape = Reshape((maxlen, embedding_dim, 1))(embedding)\n\n# 卷积层\nconv_0 = Conv2D(\n    num_filters,\n    kernel_size=(filter_sizes[0], embedding_dim),\n    padding='valid',\n    kernel_initializer='normal',\n    activation='relu'\n)(reshape)\nconv_1 = Conv2D(\n    num_filters,\n    kernel_size=(filter_sizes[1], embedding_dim),\n    padding='valid',\n    kernel_initializer='normal',\n    activation='relu'\n)(reshape)\nconv_2 = Conv2D(\n    num_filters,\n    kernel_size=(filter_sizes[2], embedding_dim),\n    padding='valid',\n    kernel_initializer='normal',\n    activation='relu'\n)(reshape)\n\n# 池化层\nmaxpool_0 = MaxPool2D(\n    pool_size=(maxlen - filter_sizes[0] + 1, 1),\n    strides=(1, 1),\n    padding='valid'\n)(conv_0)\nmaxpool_1 = MaxPool2D(\n    pool_size=(maxlen - filter_sizes[1] + 1, 1),\n    strides=(1, 1),\n    padding='valid'\n)(conv_1)\nmaxpool_2 = MaxPool2D(\n    pool_size=(maxlen - filter_sizes[2] + 1, 1),\n    strides=(1, 1),\n    padding='valid'\n)(conv_2)\n\n# 输出层\nconcatenated_tensor = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2])\nflatten = Flatten()(concatenated_tensor)\ndropout = Dropout(drop)(flatten)\noutput = Dense(units=num_classes, activation='softmax')(dropout)\n\nmodel = Model(inputs=inputs, outputs=output)\nmodel.summary()\n\nmodel.compile(\n    optimizer=Adam(lr=lr),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 回调函数","metadata":{}},{"cell_type":"code","source":"class Evaluator(Callback):\n    def __init__(self):\n        super().__init__()\n        self.best_val_f1 = 0.\n\n    def evaluate(self):\n        y_true, y_pred = list(), list()\n        for x, y in valid_generator:\n            y_true.append(y)\n            y_pred.append(self.model.predict(x).argmax(axis=1))\n        y_true = np.concatenate(y_true)\n        y_pred = np.concatenate(y_pred)\n        f1 = f1_score(y_true, y_pred, average='macro')\n        return f1\n\n    def on_epoch_end(self, epoch, logs=None):\n        val_f1 = self.evaluate()\n        if val_f1 > self.best_val_f1:\n            self.best_val_f1 = val_f1\n        logs['val_f1'] = val_f1\n        print(f'val_f1: {val_f1:.5f}, best_val_f1: {self.best_val_f1:.5f}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n    Evaluator(),\n    EarlyStopping(\n        monitor='val_loss', \n        patience=1, \n        verbose=1\n    ),\n    ModelCheckpoint(\n        'best_model.weights',\n        monitor='val_f1',\n        save_weights_only=True,\n        save_best_only=True,\n        verbose=1,\n        mode='max'\n    ),\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 拟合模型","metadata":{}},{"cell_type":"code","source":"model.fit(\n    train_generator.forfit(),\n    steps_per_epoch=len(train_generator),\n    epochs=epochs,\n    callbacks=callbacks,\n    validation_data=valid_generator.forfit(),\n    validation_steps=len(valid_generator)\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 预测","metadata":{}},{"cell_type":"markdown","source":"## 加载数据","metadata":{}},{"cell_type":"code","source":"df_test['label'] = 0\ntest_data = load_data(df_test)\ntest_generator = data_generator(test_data, batch_size)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 模型预测","metadata":{}},{"cell_type":"code","source":"result = model.predict_generator(test_generator.forfit(), steps=len(test_generator))\nresult = result.argmax(axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 将结果处理为提交的格式","metadata":{}},{"cell_type":"code","source":"\ndf_test['label'] = result\ndf_test.to_csv('submission.csv', index=False, columns=['label'])","metadata":{},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}